[![GitHub watchers](https://img.shields.io/badge/tulip--lab-Pattern--Classification-brightgreen)](../README.md)
[![GitHub watchers](https://img.shields.io/badge/Module-Foundations-orange)](README.md)

# Math Foundations of PR

In this module, a number of foundational concepts and methods related with `Pattern Classification` will be reviewed. Typically, probability and statistics, linear algebra, optimization are the math foundations for many modern PR methods. It is essential that you work through all information here in order to fully enjoy the later sessions of this unit. 

## :notebook_with_decorative_cover: Lecture Slides Handouts

### Probability and Statistics

- [Lecture A: Probability and Statistics](https://github.com/tulip-lab/handouts/blob/main/PR/PR-S01A.pdf) 
- [Lecture B: Bayesian Methods in Machine Learning](https://github.com/tulip-lab/handouts/blob/main/PR/PR-S01B.pdf) :ideograph_advantage: :star:
- [Lecture C: Probability Theory and Inequalities](https://github.com/tulip-lab/handouts/blob/main/PR/PR-S01C.pdf)
- [Lecture D: Statistical Inference](https://github.com/tulip-lab/handouts/blob/main/PR/PR-S01D.pdf)

### Linear Algebra :accept:

- [Lecture E: Linear Model and Matrix](https://github.com/tulip-lab/handouts/blob/main/PR/PR-S01E.pdf)
- [Lecture F: Matrix Factorization (1)](https://github.com/tulip-lab/handouts/blob/main/PR/PR-S01F.pdf)
- [Lecture G: Matrix Factorization (2)](https://github.com/tulip-lab/handouts/blob/main/PR/PR-S01G.pdf)

### Convex Optimization


- [Lecture H: Convex Optimization](https://github.com/tulip-lab/handouts/blob/main/SML/FLIP16.pdf)


Not all topics will be gone through in the lecture classes, and the unit chair will decide which one(s) to cover, based on the cohort's background and interests. Those topics marked by :star: will be covered in the lecture classes. 